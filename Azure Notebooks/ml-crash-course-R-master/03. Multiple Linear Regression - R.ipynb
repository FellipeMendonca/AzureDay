{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "Exercise 3 - Multiple Linear Regression\n===\n\nFrom the previous exercise, we know that customers are happier with chocolate bars that are heavier and have a high percentage of cocoa. Customers may feel differently when they have to pay more for these bars though.\n\nIn this exercise, we will try to find the chocolate bar that best suits customers, taking into account cocoa percentage, weight, and cost, using multiple linear regression.\n\n#### Run the cell below to start installing the necessary packages."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Run this first! It might take a little while to load...\n\n# Loads `tidyverse` and `plot3D` packages for graphing capabilities\nsuppressMessages(install.packages(\"tidyverse\"))\nsuppressMessages(library(\"tidyverse\"))\nsuppressMessages(library(\"plot3D\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Step 1\n---\n\nFirst, let's load the libraries we will require for this exercise, and a new chocolate bar data set that includes the feature `cost`. We will then inspect the data that we loaded.\n\n> _It is good practice to \"sanity check\" your data objects regularly in R, i.e. check the structure of your object using `str`, and print samples of your output regularly using `head` and `tail`. Sanity checking helps prevent errors downstream, and is useful for debugging code._\n\n### In the cell below replace:\n#### 1. `<checkData1>` with `str(choc_data)`\n#### 2. `<checkData2>` with `head(choc_data)`\n#### 3. `<checkData3>` with `tail(choc_data)`\n#### then __run the code__."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Loads the new chocolate data for multiple linear regression and save it to the variable name `choc_data`\nchoc_data <- read.delim(\"Data/chocolate data multiple linear regression.txt\")\n\n###    \n# REPLACE <checkData1> WITH str(choc_data) TO CHECK THE STRUCTURE OF choc_data.\n###\n<checkData>\n###\n\n###\n# REPLACE <checkData2> WITH head(choc_data) TO INSPECT THE START OF THE DATA.\n###\n<checkData>\n###\n\n###\n# REPLACE <checkData3> WITH tail(choc_data) TO INSPECT THE END OF THE DATA.\n###\n<checkData>\n###",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Our new data set `choc_data` contains 100 observations and 4 variables: weight, cocoa percent, cost, and customer happiness.\n\nStep 2\n---\n\nPreviously we found that customers like a high percentage of cocoa and heavier bars of chocolate. Large bars of chocolate cost more money, though, which might make customers less inclined to purchase them.\n\nLet's perform a simple linear regression to see the relationship between __customer happiness__ and chocolate bar __weight__ when the cost of the chocolate was taken into consideration for the survey.\n\n** Run the code block below. You do not need to edit the code before running it. **"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Run this!\n\n# DO NOT EDIT THIS CODE BLOCK\n\n# Use function from Exercise 2 to generate a simple linear regression model then graph the result\nlin_reg_choc <- function(x, y, my_data){\n    \n    x_arg <- my_data[ , substitute(x)]\n    y_arg <- my_data[ , substitute(y)]\n    \n    # Perform linear regression using `lm` (stands for linear models) function\n    lm_choc <- lm(formula = y_arg ~ x_arg, data = my_data)\n    \n    # Save lm_choc to the workspace\n    lm_choc <<- lm_choc\n    \n    # Create scatter plot of choc_data together with linear model\n    ggplot(data = my_data, aes_string(x = x, y = y)) +\n    geom_point() +\n    # Add line based on linear model\n    geom_abline(intercept = lm_choc$coefficients[1], \n                slope = lm_choc$coefficients[2],\n                colour = \"red\") +\n    # x-axis label remains constant\n    xlab(\"Customer happiness\") +\n    # y-axis label; use `gsub` function to remove underscore from \n    ylab(gsub(\"_\", \" \", y)) +\n    # graph title\n    ggtitle(paste(\"Customer satisfaction with chocolate bars given\", gsub(\"_\", \" \", y))) +\n    theme(plot.title = element_text(hjust = 0.5))\n    \n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Change `<yData>` to `\"weight\"` and run the code."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Call our custom function to run simple linear regression and plot the results\n\n###\n# REPLACE <yData> BELOW WITH \"weight\" (INCLUDING THE QUOTATION MARKS)\n###\nlin_reg_choc(x = \"customer_happiness\", y = <yData>, my_data = choc_data)\n###",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Customer happiness still increases with larger bars of chocolate. However, many data points (black) are a long way from our linear regression model (red line). This means that our model doesn't describe the data very well. It is likely that there are other features of the chocolate bars that are influencing customer happiness.\n\nRepeat the exercise looking at `cocoa_percent`, you should see a similar trend.\n\n#### Replace the `<yData>` with `\"cocoa_percent\"` and run the code."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Call our custom function to run simple linear regression and plot the results\n###\n# REPLACE <yData> BELOW WITH \"cocoa_percent\" (INCLUDING THE QUOTATION MARKS)\n###\nlin_reg_choc(x = \"customer_happiness\", y = <yData>, my_data = choc_data)\n###",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Step 3\n---\n\nWe can check how well our data fit our simple linear regression model by obtaining the R² values. R² values range between 0 - 1, where 1 is a perfect fit. What is a \"good\" or \"bad\" fit depends on several things, but for this exercise, numbers below 0.3 will mean a poor fit.\n\nThe linear model for simple linear regression we just ran, \"cocoa percent vs. customer happiness\", is saved under `lm_choc`. Let's determine the R² value of this model. \n\n** Run the code below (you don't need to edit it).**"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Extract R² value from linear model\nprint(summary(lm_choc)$r.squared)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We obtain an R² value < 0.3, which means our simple linear model \"cocoa percent vs. customer happiness\" is a poor fit of the data. \n\nTo check the R² value for the \"weight vs. customer happiness\" model:\n\n** 1. In the 2nd code block in Step 2, replace `cocoa_percent` with `weight`, then run this block.**\n\n** Run the code block in Step 3. **\n\nThis will over-write the linear model saved to `lm_choc`. You should obtain an R² value of 0.1887701, which is also < 0.3, so we should create a better model for our data.\n\nStep 4\n---\n\nThe problem with our chocolate bar survey is that the chocolate bar variables aren't controlled; cost, bar weight, and cocoa percent are different for every chocolate bar.\n\nWe want to see the relationship between cocoa content and customer happiness, but cost and block weight are also influencing customer happiness.\n\nWe *could* run another survey, giving away chocolate bars that are all the same weight for free (i.e. weight and cost are constant), and ask people how happy they are with the chocolate bar given varying percentages of cocoa. However, this would be expensive and time consuming.\n\n__Alternatively, we can use multiple linear regression__. Multiple linear regression gives us the relationship between each _feature_ and customer happiness. These are provided as _coefficients_ (slopes). Positive numbers indicate a positive relationship (i.e. customer happiness increases as this feature increases), negative numbers indicate a negative relationship (customer happiness decreases as this feature increases). Unlike _simple_ linear regression, these relationships should be independent. That means that our relationship between cocoa percentage and customer happiness should not be influenced strongly by bar weight or cost. \n\n#### Change the formula for multiple linear reqression by replacing `<addCostPercentHere>` with `cost` and run the code."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "###\n# IN THE LINE BELOW REPLACE <addCostPercentHere> WITH cost\n###\nlm_choc_mlr <- lm(formula = customer_happiness ~ weight + cocoa_percent + <addCostPercentHere>, \n                  data = choc_data)\n###\n\n# Print the coefficients (slopes) of our new model\nsummary(lm_choc_mlr)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Inspect the \"Coefficients\" heading within the results summary of our multiple linear regression model. In particular, look at the values in the \"Estimate\" column, which represent the estimate of the coefficients. Are the values positive or negative?\n\nThe coefficients for `weight` and `cocoa_percent` are both positive, which means they both independently increase customer happiness. However the coefficient for cost is negative, which means increases in cost decrease customer happiness.\n\nThe R² value (2nd last line of results summary) is also higher than before. This means our multiple linear regression model fits the data better than our simple linear regression models.\n\nStep 5\n---\n\nFrom our linear regression, we have an equation, `lm_choc`, that predicts customer happiness. It looks like so:\n\n`customer_happiness = -9.34 + weight * 0.106 + cocoa_percent * 31.9 + cost * -1.31`\n\nWe might also know that, for our company, the cost of manufacturing and shipping each bar can be calculated as:\n\n`cost = (0.05 * weight + weight * cocoa_percent)^2 * 0.0004`\n\nFrom this, we can calculate the best bar for our customers, by balancing the cost against how happy the customer is likely to be with this product. Let's plot this in 3D to see what our optimum chocolate bar should be.\n\n*** Run the code below. You do not need to edit the code. ***"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# DO NOT EDIT THE CODE\n\n# Calculate customer happiness for a given bar of chocolate \n# Use our multiple linear regression model `lm_choc_mlr`\nchoc_data_mlr <- \n    choc_data %>%\n    # Calculate adjusted cost as stated in equation above\n    mutate(cost_adj = (0.05 * weight + weight * cocoa_percent)^2 * 0.0004) %>% \n    # Calculate customer happiness based on multiple linear regression model `lm_choc_mlr`\n    mutate(cust_happ_mlr = coef(lm_choc_mlr)[\"(Intercept)\"] + (weight * coef(lm_choc_mlr)[\"weight\"]) +\n    (cocoa_percent * coef(lm_choc_mlr)[\"cocoa_percent\"]) + \n    (cost_adj * coef(lm_choc_mlr)[\"cost\"]))\n\n# Sanity check our data\nhead(choc_data_mlr)\n\n# Load package `plot3D` to create 3D scatter plot\n\nscatter3D(x = choc_data_mlr$weight, y = choc_data_mlr$cocoa_percent, \n          z = choc_data_mlr$cust_happ_mlr, bty = \"g\", \n          col = gg2.col(alpha = 0.75), pch = 16, theta = 45, phi = 30,\n          xlab = \"Weight (x)\", ylab = \"Cocoa percent (y)\", zlab = \"Customer happiness (z)\",\n          clab = \"Customer\\nhappiness\", ticktype = \"detailed\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In the 3D scatter plot above, the colour scheme is represented by customer happiness, with higher values coloured as dark grey. We can see that our optimum chocolate bar should be around 100 g and contain a high amount of cocoa. For large bars of chocolate, a cocoa content of around 50% appears to be ideal.\n\nNote how this result is different to our earlier exercise using _simple_ linear regression. With that, we assumed a large bar with a very high amount of cocoa was what customers would want.\n\nConclusion\n---\nThat's it! You can go back to the course now and click on __'Next Step'__ to carry on with our introduction to regression."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "r",
      "display_name": "R",
      "language": "R"
    },
    "language_info": {
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.5.3",
      "file_extension": ".r",
      "codemirror_mode": "r"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}